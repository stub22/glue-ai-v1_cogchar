<html>
<head>
	<title>CogChar - Cognitive Character Software</title>
    <link href="styles.css" rel="stylesheet" type="text/css"/>
<!-- 
The cascade defines an ordered sequence of style sheets where rules in later sheets have greater precedence than earlier ones. 
-->	
<script type="text/javascript">

  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-2847642-5']);
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();

</script>
</head>
<body>
<div id="page-heading">CogChar - Cognitive Character Software</div>
<hr/>
<div id="navigationBlock">
  <ul>
    <li> <a href="index.html" id="navCurrent">About</a> </li>
	<li> <a href="https://www.assembla.com/space/cogchar">Workspace</a></li>
  </ul>
</div>
<hr/>
<p>
CogChar is an open source cognitive character technology platform.
<br/>Our characters may be physical (robots), virtual, or both.
<br/>Applications in therapeutics, education, research, and fun!
</p>

<h4>Key Features</h4>
<ul>
	<li><b>Fusion of sensor and symbol streams</b>, applied to self-image and model of world.</li>
	<ul><li>Character sees, hears, touches and knows in many related symbolic and physical/virtual/numeric dimensions.</li>
		<li>My left-eye camera sees some pixels, some of which are recognized as a face, which may be matched to a name, which I may choose to say, producing a certain sound...</li>
		<li>I am standing on a floor, so my feet feel pressure from the floor.  I am holding my torso erect above my legs, and my head above my torso.  I am looking at a person called Samantha.  I can describe these facts to you in spoken words, and you can also see these facts reflected in my physical/virtual display, because they are coming from the same world-image, built from the current fused estimate of all available information (both physical and symbolic).</li>

	</ul>

	<li><b>Blended adaptive estimators and controllers</b></li>
		<ul><li>Run any numeric and symbolic learning algorithms you have heard of (bayesian, neural, genetic, you name it),
				using Java, Scala, R, Weka, Hadoop.</li>
			<li>Cogchar provides: Metadata-driven analysis and update of 1) pruned immutable trajectory logs and 2) mutable (markovian) state vectors.</li>
		</ul>
	<li><b>Rendering mind and body together</b></li>
	<ul><li>Interact with visualizations of character's body, mind, and environment, overlapped in interesting ways (what's inside the character's left ear right now?)</li>
		<li>Standard OpenGL 3D display for any compatible device (computer, tablet, smartphone, game console)</li>
	</ul>
	
	<li><b>Ongoing conversation coordination</b></li>
		<ul><li>Keep track of many conversation partners over any length of time (minutes to years).</li>
			<li>Consult reference sources during conversations, and decide which ones to mention.</li>
			<li>Conversation is integrated with embodiment, self-image, and world model.</li>
		</ul>
</ul>
	


<h4>Technical Summary</h4>
<ul>
	<li>For the big picture, please see
		<ol>
			<li>Dependencies diagram below this bullet list.</li>
			<li> 
<a href="https://www.assembla.com/spaces/friendularity/wiki/ArchOverviewPresentation">Architecture + dependencies</a> 
presentation on the experimental <a href="http://www.friendularity.org">Friendularity.org</a> site.</li>
		</ol>
	</li>

	<li>Java, Scala, and OSGi core technology</li>
	<li>Symbolic metadata smarts (RDW/OWL/SPARQL) from <a href="http://www.appdapter.org">Appdapter</a> platform</li>
	<li>3D character rendering to OpenGL using <a href="http://jmonkeyengine.com">JMonkey Game Engine</a>, LWJGL, BulletPhysics</li>
	<li>Connection with many popular open source mathematics, AI and robotics tools</li>
	<ul><li><a href="http://www.robokind.org">Robokind</a> - Binding to physical humanoid robot features</li>
	<li><a href="http://code.google.com/p/opensim4opencog/">Cogbot</a> - Advanced conversation features, emotion simulation, and links to online virtual worlds</li>
	</ul>
	<li>Integration with MIDI + SMPTE music+video technology for action mapping, triggering, and synchronization</li>
	<li>Serialization to <a href="http://avro.apache.org">Avro</a>, messaging over <a href="http://www.amqp.org">AMQP</a>, cloud integration via <a href="http://hadoop.apache.org">Hadoop</a></li>
	<li>Planned compatibility with Android platform</li>
</ul>
<h4>For More Information</h4>
<ul>
	<li><a href="https://www.assembla.com/code/cogchar/subversion/nodes">Source tree</a> (maven is not strictly required, but makes life easier, for Us!)</li>
	<li>Somewhat old <a href="http://www.jarvana.com/jarvana/doc?search_type=javadoc_project&project=org.cogchar">Javadocs</a> on Jarvana, be sure to check version, there is a lag from Maven Central.</li>	
	<li>Please visit the <a href="https://www.assembla.com/spaces/cogchar">Wiki</a> in our workspace.</li>
	<li>Visit the <a href="http://www.appdapter.org">Appdapter</a>, <a href="http://www.robokind.org">Robokind</a>, and <a href="http://www.jmonkeyengine.com">JMonkey-Engine</a> websites.</li>
	<li>You may ask questions and discuss the software using the  <a href="http://groups.google.com/group/cogchar-users">cogchar-users</a> google group.</li>
</ul>
<img src="diag/Cogchar_Project_Dependencies.png"/>

<table style="background-color: #fff; padding: 5px;" cellspacing=0>
  <tr><td>
  <img src="http://groups.google.com/intl/en/images/logos/groups_logo_sm.gif"
         height=30 width=140 alt="Google Groups">
  </td></tr>
  <tr><td style="padding-left: 5px;font-size: 125%">
  <b>cogchar-users</b>
  </td></tr>
  <tr><td style="padding-left: 5px">
  <a href="http://groups.google.com/group/cogchar-users">Visit this group</a>
  </td></tr>
</table>
</body>
</html>